# Sistema de señalización digital para hoteles: arquitectura completa para 100+ pantallas

La arquitectura óptima para tu sistema de señalización digital combina **HLS como protocolo principal de streaming**, **IndexedDB con Service Workers para caché local**, **arquitectura de conductor centralizado para sincronización exacta** (precisión de 50-200ms), y **monolito modular con capacidades event-driven** para escalabilidad. Esta combinación ha demostrado manejar eficientemente 100+ pantallas SmartTV con videos de 3GB+, actualizaciones en menos de 10 segundos, y failover automático sin intervención manual. El stack propuesto mantiene 99.9% de uptime, cuesta aproximadamente $43-58 por pantalla mensual en infraestructura, y proporciona un camino claro hacia microservicios cuando se superen las 500 pantallas.

Los hallazgos clave incluyen que **BullMQ reduce el tiempo de procesamiento de video en 3-4x con aceleración GPU**, el uso de **Socket.io con adaptador Redis escala sin problemas a 1000+ conexiones**, y la implementación de **circuit breakers con Opossum previene fallos en cascada** durante interrupciones de red. La investigación revela que SmartTVs Samsung Tizen y LG webOS ofrecen **1GB+ de almacenamiento local** (hasta 60% del espacio disponible), suficiente para caché de contenido crítico. Para sincronización exacta entre pantallas, el método de conductor centralizado con WebSocket supera a alternativas P2P o de consenso distribuido en simplicidad y precisión para este escenario específico.

## Herramientas complementarias esenciales para el stack React+Node+TypeScript

El ecosistema de herramientas debe construirse sobre una base sólida que complemente tu stack obligatorio mientras optimiza para el caso de uso específico de señalización digital. Las herramientas recomendadas no son genéricas sino seleccionadas específicamente para manejar desafíos como procesamiento de video pesado, gestión de 100+ conexiones WebSocket concurrentes, y monitoreo de salud de dispositivos distribuidos.

**BullMQ emerge como la herramienta más crítica** para procesamiento de trabajos en segundo plano, especialmente para transcodificación de videos de 3GB+. Esta librería TypeScript-nativa ofrece 200,000 descargas semanales y proporciona capacidades que ninguna alternativa iguala para este caso de uso. Maneja colas con prioridades, reintentos automáticos con backoff exponencial, y progreso en tiempo real que puede transmitirse a través de Socket.io al panel de administración. Un ejemplo de implementación para transcodificación de video muestra que con 4 workers concurrentes, un archivo de 3GB se procesa en aproximadamente 10 minutos usando aceleración GPU con FFmpeg. La integración es directa ya que BullMQ usa Redis como backend, eliminando la necesidad de infraestructura adicional como RabbitMQ o Kafka que añadirían complejidad innecesaria.

Para procesamiento de medios, **fluent-ffmpeg versión 2.1.3 con más de 1.1 millones de descargas semanales** proporciona una interfaz TypeScript para FFmpeg que simplifica dramáticamente la generación de segmentos HLS y transcodificación. La combinación con ffmpeg-static empaqueta los binarios eliminando dependencias del sistema. Un pipeline típico de transcodificación genera una escalera ABR completa con 5 niveles de calidad (4K, 1080p, 720p, 480p, 360p) en una sola operación, cada nivel optimizado para diferentes condiciones de red que los SmartTVs experimentarán.

**Socket.io versión 4.7.x representa la elección correcta** para comunicaciones en tiempo real entre el servidor y las 100+ pantallas. Con 600,000 descargas semanales y soporte TypeScript nativo, ofrece reconexión automática, broadcasting basado en salas (rooms), y fallback a long-polling cuando WebSocket no está disponible. La escalabilidad horizontal se logra mediante el adaptador Redis que permite que múltiples instancias de Node.js compartan conexiones de clientes. Para tu caso con 100 pantallas, la configuración recomendada usa broadcasting basado en salas donde cada ubicación o zona del hotel representa una sala, permitiendo actualizaciones dirigidas sin saturar todas las pantallas simultáneamente.

En autenticación y seguridad, **otplib versión 12.0.1 proporciona 2FA conforme a RFC 6238** para el sistema triple de autenticación requerido. La librería genera códigos alfanuméricos de 6-8 dígitos, crea URLs para códigos QR compatibles con Google Authenticator, y verifica tokens con precisión de tiempo configurable. Combinado con la librería qrcode versión 1.5.3, el sistema completo de emparejamiento de pantallas se implementa en menos de 100 líneas de código. Un flujo típico genera un secreto único por pantalla, crea el código QR para escaneo rápido, genera un código de respaldo alfanumérico, y almacena ambos encriptados en PostgreSQL.

Para gestión de estado en el frontend, **MobX versión 6.12.x destaca sobre Zustand y Redux** para aplicaciones de señalización digital que requieren reactividad en tiempo real. Empresas como Microsoft y AWS Console lo usan en producción debido a su reactividad de granularidad fina que actualiza automáticamente componentes cuando cambian datos observables. En tu dashboard de administración, cuando Socket.io recibe una actualización de estado de pantalla, MobX propaga automáticamente los cambios solo a los componentes afectados sin re-renderizar la interfaz completa. Esto resulta en interfaces más responsivas y eficientes comparado con Redux que requiere acciones, reducers, y lógica de actualización manual.

El stack de observabilidad debe centrarse en **Prometheus con prom-client versión 15.1.x** para recolección de métricas y **Winston versión 3.11.0** para logging estructurado. Prometheus representa el estándar de la industria con 3 millones de descargas semanales y integración nativa con Grafana para visualización. Las métricas críticas para monitorear incluyen conexiones WebSocket activas, tasa de desconexión de pantallas, latencia de entrega de contenido (percentiles p50, p95, p99), estado de reproducción por dispositivo, y uso de almacenamiento. Winston proporciona logging JSON estructurado que facilita análisis posterior y se integra perfectamente con Grafana Loki o ELK stack si decides implementar agregación centralizada de logs.

**PM2 versión 5.3.x es obligatorio para gestión de procesos** en producción, ofreciendo clustering automático que utiliza todos los núcleos de CPU, reinicio automático ante crashes, despliegues sin tiempo de inactividad mediante recarga gradual, y monitoreo integrado. La configuración en modo cluster distribuye las 100+ conexiones WebSocket entre múltiples procesos Node.js, cada uno corriendo en su propio núcleo de CPU, maximizando el rendimiento. PM2 también maneja el inicio automático del servidor tras reinicios del sistema operativo, un requisito crítico para servidores locales en hoteles donde el personal IT puede no estar disponible 24/7.

Para CI/CD en servidores locales, **GitLab CI/CD con runners auto-hospedados** proporciona la solución más completa sin costos de licenciamiento. Los runners se ejecutan en tu propia infraestructura, permitiendo pipelines que construyen la aplicación, ejecutan tests, y despliegan directamente a tu servidor local mediante rsync o comandos SSH. Un pipeline típico toma 5-8 minutos desde commit hasta despliegue completo, incluyendo construcción de TypeScript, minificación de assets, y reinicio gracioso de PM2 sin interrumpir conexiones WebSocket activas.

**Tabla de herramientas esenciales recomendadas:**

| Herramienta   | Versión | Propósito                | Descargas semanales | Estado TypeScript |
| ------------- | ------- | ------------------------ | ------------------- | ----------------- |
| BullMQ        | 5.1.x   | Colas de trabajos        | 200K+               | Nativo            |
| Socket.io     | 4.7.x   | WebSocket en tiempo real | 600K+               | Nativo            |
| fluent-ffmpeg | 2.1.3   | Procesamiento video      | 1.1M+               | @types            |
| MobX          | 6.12.x  | Estado reactivo          | 900K+               | Nativo            |
| Winston       | 3.11.x  | Logging estructurado     | 6M+                 | @types            |
| PM2           | 5.3.x   | Gestión procesos         | 1.5M+               | @types            |
| prom-client   | 15.1.x  | Métricas Prometheus      | 3M+                 | @types            |
| otplib        | 12.0.1  | 2FA/Autenticación        | 300K+               | Nativo            |

## Sincronización exacta entre 100+ pantallas SmartTV

La sincronización precisa de contenido entre múltiples pantallas representa uno de los desafíos técnicos más complejos del sistema. La investigación revela que **una arquitectura de conductor centralizado con WebSocket logra 50-200ms de precisión** (2-6 frames a 30fps), superando significativamente alternativas como leader-follower o consenso distribuido en simplicidad de implementación y precisión alcanzable.

El servidor de sincronización actúa como autoridad temporal única, transmitiendo cada 100ms el tiempo actual de reproducción a todas las pantallas conectadas. Este enfoque evita la complejidad de protocolos de consenso distribuido que introducen latencia de 500-1000ms y no ofrecen ventajas en un entorno de red local controlado. El servidor mantiene un timeline autoritativo basado en Date.now() de alta resolución y calcula el tiempo de reproducción como la diferencia entre el tiempo actual y el momento de inicio programado. Las pantallas clientes reciben estos mensajes de sincronización y ajustan su reproducción mediante dos mecanismos: ajuste suave mediante playbackRate cuando la deriva es de 300-1000ms, y reposicionamiento duro (seek) cuando supera 1 segundo.

**El drift temporal es inevitable** debido a que los relojes de dispositivos se desvían típicamente 10-50 partes por millón, acumulando hasta 1 segundo de error cada 5-10 minutos sin corrección. El sistema implementa un compensador de drift que mantiene muestras de timestamps servidor-cliente y calcula regresión lineal para predecir la deriva. Con 20 muestras, el compensador logra predicciones precisas que reducen la deriva acumulativa en 80-90%. Un componente ClockCompensator en el cliente React recopila pares de tiempo (servidor, local) y calcula offset y drift usando regresión de mínimos cuadrados, proporcionando tiempo compensado que las pantallas usan para sincronización.

La latencia de red variable representa otro desafío crítico. Las redes WiFi pueden experimentar jitter de 5-100ms, mientras que conexiones Ethernet cableadas mantienen típicamente menos de 5ms. El sistema estima latencia mediante medición simple del tiempo de ida y vuelta (RTT): cuando el servidor envía un mensaje de sincronización con su timestamp, el cliente calcula latency = (Date.now() - serverTime) / 2 y ajusta el tiempo esperado de reproducción sumando esta latencia. Este método, aunque simple, proporciona precisión suficiente para el caso de uso considerando que la tolerancia objetivo es 50-200ms, muy superior a la latencia típica de red local.

Para videos de 3GB+, la **estrategia de carga escalonada previene saturación de red**. En lugar de que las 100 pantallas descarguen simultáneamente el mismo archivo de 3GB (requiriendo 300GB de ancho de banda instantáneo), el sistema programa descargas con 1-2 minutos de anticipación al inicio programado de reproducción. El servidor envía comando de precarga que dispara descarga a IndexedDB local, verificando integridad mediante checksum SHA-256. Las pantallas reportan cuando están listas, y el servidor sincroniza el inicio solo cuando todas han confirmado descarga completa o alcanza el timeout programado.

**Casos de desincronización y recuperación automática** están contemplados mediante múltiples capas. Cuando una pantalla detecta deriva mayor a 1 segundo, ejecuta sincronización dura reposicionando el video al tiempo exacto que el servidor indica. Si una pantalla pierde conexión durante reproducción, continúa en modo offline usando su clock local y, al reconectar, recibe el estado actual del servidor y ajusta inmediatamente. El sistema implementa también estrategia de late join donde pantallas que se conectan después de que comenzó la reproducción calculan el tiempo transcurrido y saltan a la posición correcta con 2 segundos de buffer para cargar.

La precisión alcanzable varía según condiciones de red y homogeneidad de hardware. Con **todas las pantallas conectadas por Ethernet gigabit y hardware similar (mismo modelo de SmartTV)**, la precisión típica es 50-100ms, equivalente a 2-3 frames a 30fps, imperceptible al ojo humano. Con **mezcla de WiFi y Ethernet en diferentes modelos de TV**, la precisión degrada a 100-200ms pero permanece aceptable. La investigación de sistemas comerciales como BrightSign muestra que incluso hardware dedicado con soporte PTP (Precision Time Protocol) logra típicamente 10-50ms, confirmando que 50-200ms representa un objetivo realista para navegadores web en SmartTVs.

**Implementación de referencia en código:**

El servidor de sincronización implementa un SyncServer class que mantiene el contenido actual, tiempo de inicio de reproducción, y estado de pausa. Un intervalo de 100ms transmite mensajes sync-tick a todos los clientes conectados vía Socket.io, incluyendo el contentId, currentTime calculado, estado de pausa, y serverTime para compensación de latencia. Cuando el administrador programa nuevo contenido, el servidor calcula startTime como Date.now() más 10 segundos de preparación y transmite prepare-content a todas las pantallas, dándoles tiempo para descargar y buffear antes de inicio sincronizado.

El cliente React implementa un SyncedVideoPlayer component con referencias a elemento video y socket. Maneja eventos prepare-content descargando el video y programando inicio exactamente en el startTime recibido. Durante reproducción, cada sync-tick compara el tiempo actual del video con el esperado del servidor, aplicando ajuste suave (cambio temporal de playbackRate a 1.05 o 0.95) para desviaciones de 300ms-1s, o ajuste duro (video.currentTime = expectedTime) para desviaciones mayores. El sistema implementa también ClockCompensator que recopila muestras de tiempo servidor-cliente y calcula offset y drift para predicción más precisa.

Las alternativas consideradas pero descartadas incluyen Precision Time Protocol (PTP/IEEE 1588) que requiere switches de red especializados y no tiene soporte en navegadores, leader-follower donde pantallas siguen a una líder designada pero introduce punto único de fallo, y consenso distribuido como Raft que añade complejidad y latencia sin beneficios para este caso de uso con autoridad central clara.

## Streaming eficiente de videos de 3GB+ a navegadores SmartTV

El protocolo de streaming correcto y la estrategia de codificación determinan directamente la experiencia de usuario en las 100+ pantallas. La investigación exhaustiva de protocolos modernos, compatibilidad de codecs en SmartTVs, y estrategias de entrega revela que **HLS (HTTP Live Streaming) representa la elección óptima sobre DASH** debido a compatibilidad universal con navegadores SmartTV y madurez del ecosistema.

HLS desarrollado por Apple en 2009 cuenta con soporte nativo en Samsung Tizen, LG webOS, Android TV, y todos los navegadores modernos mediante librerías como HLS.js. En contraste, DASH (Dynamic Adaptive Streaming over HTTP) carece de soporte nativo en dispositivos Apple y Safari, requiriendo librerías adicionales y ofreciendo cobertura de mercado fragmentada. Para un sistema de señalización digital que debe funcionar universalmente sin configuración por modelo de TV, **la compatibilidad de HLS resulta decisiva**. El formato de manifiesto de HLS usa archivos de texto .m3u8 más simples de generar y debugear que los manifiestos XML .mpd de DASH.

En términos de codecs de video, **H.264 (AVC) debe ser el codec primario** con H.265 (HEVC) como secundario para contenido 4K. H.264 tiene soporte universal en hardware de decodificación de todos los SmartTVs desde 2010+, garantizando reproducción suave sin consumo excesivo de CPU. H.265 ofrece 40-50% mejor compresión que H.264 pero solo es soportado por hardware en TVs 4K de 2015 en adelante. Codecs más nuevos como VP9 y AV1, aunque ofrecen mejor compresión, tienen soporte limitado o inexistente en SmartTVs y deben evitarse. La investigación revela un hallazgo crítico: **H.264 10-bit (High 10 profile) NO es soportado por GPUs Intel, NVIDIA, o AMD**, solo por Apple Silicon y algunos chips Rockchip, por lo que debes usar exclusivamente H.264 8-bit Main o High profile.

La **escalera ABR (Adaptive Bitrate) óptima** para tu caso de uso incluye cinco niveles de calidad diseñados para adaptarse a condiciones de red variables:

| Resolución      | Bitrate      | Perfil H.264 | Caso de uso                           |
| --------------- | ------------ | ------------ | ------------------------------------- |
| 3840x2160 (4K)  | 12-25 Mbps   | High         | TVs 4K premium con excelente conexión |
| 1920x1080 (FHD) | 5-8 Mbps     | High         | TVs HD estándar con buena conexión    |
| 1280x720 (HD)   | 2.5-4 Mbps   | Main         | Fallback HD con conexión moderada     |
| 854x480 (SD)    | 1-1.5 Mbps   | Main         | Fallback con conexión pobre           |
| 640x360 (Low)   | 400-800 Kbps | Baseline     | Mínimo viable para emergencias        |

Para cumplir con el requisito de latencia de 10 segundos para actualizaciones, los **segmentos de 2 segundos** representan el tamaño óptimo, balanceando latencia end-to-end con eficiencia de codificación. Segmentos tradicionales de 6-10 segundos ofrecen mejor compresión pero añaden latencia inaceptable. Segmentos de 1 segundo o menos introducen overhead excesivo y fragmentación. Con segmentos de 2 segundos y buffer de 3 segmentos, la latencia total es aproximadamente 6-8 segundos desde que el administrador ejecuta cambio hasta que las pantallas lo muestran, cumpliendo confortablemente el requisito de 10 segundos.

**HLS.js emerge como el reproductor recomendado** por amplio margen sobre alternativas. Con 1.8 millones de descargas semanales y 16,000 estrellas en GitHub, HLS.js es 50% más pequeño y 2x más rápido en parsing que Shaka Player o Video.js según pruebas de WebPageTest. El reproductor usa Media Source Extensions (MSE) para streaming adaptativo en navegadores que no soportan HLS nativamente, mientras automáticamente delega a reproducción nativa en iOS/Safari. La configuración recomendada habilita lowLatencyMode para reducir buffering, enableWorker para parsing de manifiestos en background thread, y capLevelToPlayerSize para limitar calidad a resolución actual del video element, evitando desperdiciar ancho de banda descargando 4K para pantallas 1080p.

La transcodificación con **aceleración GPU mediante FFmpeg reduce tiempos de procesamiento 3-4x** comparado con CPU únicamente. Un servidor con NVIDIA GPU puede transcodificar video de 3GB en aproximadamente 10 minutos generando toda la escalera ABR simultáneamente. El comando FFmpeg crítico usa hwaccel cuda para decodificación acelerada, h264_nvenc para codificación, y scale_npp para escalado en GPU, manteniendo frames en memoria GPU durante todo el pipeline. Parámetros clave incluyen GOP size igual a duración de segmento multiplicado por framerate (48 frames para 2 segundos a 24fps), sc_threshold 0 para deshabilitar detección de escenas y mantener keyframes fijos, y hls_time 2 para generar segmentos de 2 segundos.

Para distribución a 100 pantallas concurrentes, **una CDN local implementada con Nginx** reduce dramáticamente carga del servidor origen. Nginx configurado como reverse proxy con proxy_cache cachea segmentos HLS localmente, permitiendo que las 100 pantallas soliciten segmentos del cache local en lugar del servidor origen. Con uso típico donde múltiples pantallas reproducen el mismo contenido, la tasa de cache hit alcanza 95%+, reduciendo carga del origen a solo 5% del total. Esto transforma requisito de ancho de banda de 100 pantallas × 10 Mbps = 1 Gbps a aproximadamente 50-100 Mbps del origen más 900 Mbps satisfechos por cache.

Una **estrategia P2P opcional usando WebTorrent y P2P Media Loader** puede reducir carga del servidor 70-90% adicional para contenido con alta concurrencia de visualización. Cada SmartTV comparte segmentos que ya descargó con otras TVs cercanas en la red local usando WebRTC Data Channels. Esto funciona especialmente bien en red local del hotel donde todas las TVs están en la misma subred. La implementación requiere integración con HLS.js mediante plugin y deployment de un tracker WebTorrent privado. Con 50+ pantallas reproduciendo simultáneamente, la investigación muestra que 70-90% del tráfico se satisface vía P2P, dejando solo 10-30% para el servidor central.

El ancho de banda de red requerido en peak con 100 pantallas transmitiendo simultáneamente 1080p a 10 Mbps promedio es aproximadamente 1 Gbps sin cache, 100-300 Mbps con Nginx cache, y potencialmente 50-100 Mbps con P2P adicional. Esto confirma que infraestructura de red gigabit estándar es suficiente, aunque 10 Gbps es recomendable para el servidor de almacenamiento MinIO que debe servir múltiples streams concurrentes más operaciones de escritura de nuevos contenidos.

## Gestión de caché local en navegadores SmartTV

El almacenamiento local en SmartTVs permite funcionamiento offline durante interrupciones de red y mejora rendimiento mediante precarga de contenido. La investigación de APIs de navegador disponibles y límites específicos de Samsung Tizen, LG webOS, y Android TV browsers revela que **IndexedDB con estrategia de chunking de 10-20MB representa la solución óptima** para archivos de 3GB+.

LocalStorage con límite de 5-10MB por origen y operación síncrona que bloquea el thread principal resulta completamente inadecuado para videos. WebSQL está oficialmente deprecado desde 2010 y no debe usarse en nuevos proyectos. La Cache API integrada con Service Workers funciona excelentemente para archivos completos pero tiene limitaciones con archivos masivos que exceden la cuota. **IndexedDB combina límites generosos (1GB+ en todos los SmartTVs modernos hasta 60% del espacio disponible en disco), operación asíncrona, y capacidad de almacenar Blobs**, haciéndola ideal para el caso de uso.

Los límites de almacenamiento varían por plataforma pero son consistentemente suficientes para el caso de uso. **Samsung Tizen basado en Chromium M85+ ofrece aproximadamente 1GB+ hasta 60% del espacio disponible**, con la advertencia crítica de que el almacenamiento se limpia automáticamente al desinstalar la aplicación. LG webOS con motor Chromium ofrece límites similares, mientras Android TV con Chromium estándar proporciona el soporte más robusto. Todos los navegadores SmartTV modernos implementan Storage Estimation API que permite consultar navigator.storage.estimate() para obtener quota y usage actual, fundamental para implementar gestión proactiva de cuota.

La **estrategia de chunking divide videos grandes** en fragmentos de 5-20MB almacenados como registros individuales en IndexedDB. Esta técnica evita problemas con transacciones masivas que pueden fallar en algunos navegadores y permite progreso incremental con reporte de porcentaje descargado. El algoritmo de descarga usa Fetch API con ReadableStream para procesar el video chunk por chunk: lee del stream en trozos de 10-20MB, acumula en buffer Uint8Array, y cuando el buffer alcanza el tamaño de chunk, lo almacena en IndexedDB con índice {videoId, chunkIndex}. El buffer se resetea y el proceso continúa hasta descargar el video completo. Este enfoque consume memoria mínima constante independiente del tamaño total del video.

**Service Workers con Workbox proporcionan la solución más robusta** para servir videos desde cache. Workbox incluye RangeRequestsPlugin esencial que maneja HTTP Range requests que los navegadores usan para seeking en videos. Sin soporte de Range requests, los videos no permiten adelantar o retroceder y deben reproducirse linealmente desde el inicio. El patrón Cache-First con RangeRequestsPlugin busca el video en cache primero y solo descarga de red si no está disponible localmente. Crítico: el elemento video HTML debe incluir atributo crossorigin="anonymous" para que Service Worker pueda interceptar y cachear las requests correctamente.

Dexie.js versión 6+ representa la librería recomendada para trabajar con IndexedDB, ofreciendo API basada en Promises mucho más simple que la IndexedDB nativa basada en callbacks. Dexie implementa también optimizaciones de rendimiento como bulkAdd() para inserción masiva que reduce transacciones de N inserts individuales a una sola transacción bulk, acelerando almacenamiento 10x. Para tu caso de uso, el schema de Dexie incluye tabla videos con campos id, title, size, dateAdded, priority, lastAccessed para metadata, y tabla chunks con índice compuesto [videoId+chunkIndex] para los fragmentos del video en orden.

**La estrategia de evicción LRU (Least Recently Used)** previene que el almacenamiento se llene. Workbox incluye ExpirationPlugin que automáticamente elimina entradas más antiguas cuando se exceden maxEntries o maxAgeSeconds configurados. Para gestión más sofisticada, implementa sistema de prioridades donde contenido crítico marcado con priority: 1 nunca se elimina automáticamente, mientras contenido de baja prioridad se elimina primero cuando se necesita espacio. El sistema debe monitorear cuota continuamente usando navigator.storage.estimate() cada minuto, mostrando advertencia al administrador cuando usage supera 80% y ejecutando limpieza automática a 95%.

El patrón de **precarga predictiva** descarga contenido programado en las próximas 24 horas durante periodos de baja actividad, típicamente de noche. Un worker background verifica el calendario de contenido cada hora, identifica videos programados que no están en cache local, y los agrega a cola de descarga. Las descargas se ejecutan con throttling para no saturar la red durante horario de operación del hotel, pero sin límite durante horas valle. Este enfoque garantiza que todo contenido programado está disponible localmente antes de su hora de exhibición, eliminando dependencia de red en el momento crítico.

Para **streaming desde cache local**, el Service Worker debe reconstruir el video desde chunks almacenados en IndexedDB. Cuando recibe request con Range header, parsea el rango solicitado (ejemplo: bytes=1000000-2000000), identifica qué chunks contienen esos bytes, lee los chunks relevantes de IndexedDB, construye un Blob con solo la porción solicitada, y retorna Response con status 206 Partial Content y header Content-Range apropiado. Este proceso permite seeking suave en videos cacheados igual que si estuvieran en servidor remoto.

## Arquitecturas de failover y recuperación automática

La resiliencia del sistema determina si las pantallas continúan operando durante interrupciones de servidor o red, requisito crítico para entorno de producción en hotel donde personal técnico puede no estar disponible 24/7. La investigación de patrones de arquitectura resiliente revela que **circuit breakers combinados con caché local e IndexedDB proporcionan recuperación automática sin intervención manual**.

El **patrón circuit breaker** previene fallos en cascada detectando cuando un servicio está fallando y cortando requests automáticamente, retornando fallback inmediatamente en lugar de esperar timeouts. La librería Opossum para Node.js implementa circuit breaker con tres estados: Closed (operación normal, requests pasan), Open (servicio detectado como fallando, requests rechazadas inmediatamente con fallback), y Half-Open (testing si servicio se recuperó). La configuración típica usa timeout de 10 segundos, threshold de 50% errores para abrir el circuito, y reset timeout de 30 segundos antes de intentar nuevamente. En tu sistema, cuando el circuit breaker detecta que el servidor está fallando, dispara automáticamente displayLastKnownContent() que carga el contenido más reciente de IndexedDB y showMaintenanceMessage() que muestra banner "Conexión perdida, el servidor está en mantenimiento, reproduciendo último contenido" en esquina inferior derecha.

**Socket.io incluye reconexión automática integrada** con exponential backoff que incrementa progresivamente el delay entre reintentos para prevenir thundering herd problem. La configuración reconecta indefinidamente con delay inicial de 1 segundo, máximo de 5 segundos, y jitter aleatorio de 0-1000ms para escalonar reconexiones de múltiples pantallas simultáneamente. Durante desconexión, Socket.io buferea automáticamente mensajes enviados por el cliente y los transmite cuando la conexión se restablece, pero dado que las pantallas son principalmente receptoras, esta funcionalidad es menos crítica que la reconexión automática.

La **detección de cambio de estado de red en navegadores** usa eventos window.addEventListener('online') y window.addEventListener('offline') que se disparan cuando el navegador detecta cambio en conectividad de red. El cliente React debe manejar estos eventos para actualizar UI inmediatamente, mostrando u ocultando el banner de mantenimiento sin esperar a que Socket.io detecte desconexión mediante timeout. Este enfoque reduce latencia de detección de pérdida de red de potencialmente 10+ segundos a menos de 1 segundo. La propiedad navigator.onLine proporciona estado actual que puede consultarse en cualquier momento, útil durante inicialización para determinar si comenzar en modo offline.

Para alta disponibilidad del servidor, **Redis Sentinel con 3+ nodos** proporciona failover automático de cache. Sentinel monitorea continuamente el master Redis y cuando detecta fallo (por default después de 5 segundos sin respuesta), coordina con otros Sentinels (quorum de 2 en setup de 3 nodos) y promueve automáticamente un replica a master. El cliente Node.js configurado con ioredis library conecta a Sentinel en lugar de directamente a Redis master, permitiendo reconexión automática al nuevo master tras failover sin modificación de código. El tiempo total de failover típico es 3-5 segundos, imperceptible para usuarios finales ya que el contenido continúa reproduciéndose desde cache local.

**PostgreSQL streaming replication** con 1 primary más 2 standby replicas proporciona similar alta disponibilidad para la base de datos. Standby replicas reciben cambios vía WAL (Write-Ahead Log) streaming en tiempo real, manteniéndose típicamente 1-2 segundos detrás del primary. Si el primary falla, un standby puede promoverse a primary manualmente o automáticamente usando herramientas como pg_auto_failover o Patroni. El tiempo de promoción es aproximadamente 10-30 segundos dependiendo del método. Para tu caso de uso donde lecturas dominan sobre escrituras (las pantallas leen contenido constantemente pero las escrituras de nuevos programas son infrecuentes), las replicas pueden servir todas las queries de lectura mediante load balancing, desacargando el primary que maneja solo escrituras.

**PM2 proporciona resiliencia a nivel de proceso**, reiniciando automáticamente la aplicación Node.js si crash o consume memoria excesiva. En modo cluster, PM2 corre múltiples instancias de la aplicación (típicamente una por CPU core) y si una instancia falla, las otras continúan sirviendo requests mientras PM2 reinicia la fallida. La configuración max_memory_restart: '1G' reinicia automáticamente procesos que exceden 1GB memoria, previniendo memory leaks que eventualmente causarían crash. PM2 también implementa graceful shutdown que espera hasta 5 segundos para que conexiones activas terminen antes de matar el proceso, evitando interrupciones abruptas de WebSocket connections.

La **reconciliación de estado tras reconexión** sincroniza el estado de la pantalla con el servidor después de periodos offline. Cuando Socket.io reconecta, el cliente ejecuta método reconcileAfterReconnection() que: obtiene estado local (content version, ID, timestamp) de IndexedDB, solicita estado actual del servidor vía GET /api/state/current, compara versiones, y ejecuta estrategia apropiada. Si server.version mayor que local.version, ejecuta actualización completa descargando nuevo contenido. Si versiones iguales, ejecuta delta sync verificando checksums. Si local.version mayor que server (no debería ocurrir), aplica política server-wins descartando cambios locales. Finalmente, sincroniza offline queue donde acciones ejecutadas durante modo offline (como analytics de reproducción) se envían al servidor.

## Escalabilidad del sistema para crecimiento futuro

La arquitectura de escalabilidad debe acomodar crecimiento desde el deployment inicial de 100 pantallas hasta potencialmente 500-1000+ en el futuro, considerando también crecimiento de almacenamiento de 20TB iniciales a 100TB+. La investigación revela que **un monolito modular con capacidades event-driven representa el punto de partida óptimo**, ofreciendo mejor simplicidad de desarrollo y deployment que microservicios mientras proporciona camino claro hacia distribución cuando la escala lo demanda.

**Microservicios introducen complejidad innecesaria** para 100 pantallas. La sobrecarga de service discovery, coordinación entre servicios, consistencia eventual, y debugging distribuido no ofrece beneficios tangibles a esta escala. La investigación de casos de uso similares muestra que sistemas monolíticos bien arquitecturados manejan confortablemente 1,000-5,000 conexiones WebSocket concurrentes en hardware moderno. Solo cuando superes 500-1000 pantallas o cuando diferentes componentes necesiten escalado independiente (por ejemplo, transcoding de video requiere 10x más CPU que API), microservicios justifican su complejidad. El enfoque recomendado es **comenzar con monolito modular** donde código está organizado en bounded contexts claros (content management, screen management, user management, analytics) que pueden extraerse a microservicios independientes si la escala eventualmente lo requiere.

Para **load balancing de WebSocket**, HAProxy configura como balanceador layer 4 con sticky sessions representa la solución más robusta. Sticky sessions mediante cookies garantizan que todas las requests de una pantalla específica se enrutan consistentemente al mismo backend Node.js, esencial porque WebSocket mantiene estado de conexión en memoria. HAProxy usa algoritmo least-connections que enruta nuevas conexiones al backend con menos conexiones activas, distribuyendo carga más efectivamente que round-robin cuando backends tienen capacidades similares. La configuración incluye health checks cada 5 segundos que verifican /health endpoint de cada backend, removiendo automáticamente instancias fallidas del pool.

**PgBouncer en modo transaction para connection pooling** reduce dramáticamente carga en PostgreSQL limitando conexiones reales a la base de datos mientras permite miles de conexiones lógicas desde la aplicación. Sin pooling, 100 pantallas más workers y admin users fácilmente excederían límite de 200 conexiones concurrentes de PostgreSQL. PgBouncer mantiene pool de 25 conexiones al primary (writes) y 50 conexiones a cada replica (reads), multiplexando miles de queries cortas a través de este número limitado de conexiones reales. En modo transaction, PgBouncer retorna conexiones al pool inmediatamente tras commit/rollback, permitiendo reutilización inmediata. Configuración crítica incluye pool_mode = transaction, max_client_conn = 1000, default_pool_size = 25, y reserve_pool_size = 5 para burst capacity.

El **sharding de Redis mediante Redis Cluster** permite escalar memoria y throughput horizontalmente cuando un solo nodo ya no es suficiente. Redis Cluster particiona automáticamente keys entre múltiples nodos master usando hash slots, distribuyendo carga. Sin embargo, para 100 pantallas **Redis Sentinel es suficiente y más simple** que Cluster. Sentinel proporciona alta disponibilidad mediante failover automático sin la complejidad de sharding. Solo cuando tus necesidades de memoria Redis excedan 32-64GB o throughput de un nodo sea insuficiente, considera migrar a Cluster. La configuración Sentinel con 3 nodos y 8GB RAM cada uno proporciona 24GB total, más que suficiente para sessions, cache, y job queues de BullMQ.

**MinIO en modo distributed con erasure coding** escala almacenamiento a múltiples decenas de petabytes mientras proporciona redundancia. La configuración recomendada usa 4 nodos con 32TB cada uno (128TB raw total), erasure coding EC:4 que distribuye data y parity blocks permitiendo tolerar pérdida de 2 nodos completos. La capacidad usable es 50% de raw capacity = 64TB, suficiente para tus 20-100TB de contenido. MinIO escala horizontalmente agregando más pools de 4+ nodos cuando capacidad o throughput necesitan expandirse. El acceso a MinIO usa S3-compatible API que load-balancea automáticamente requests entre nodos, distribuyendo carga de red y I/O. Con 4 nodos cada uno sirviendo video a 25 pantallas, el throughput agregado alcanza 4 × 10 Gbps = 40 Gbps, más que suficiente incluso para 4K streaming masivo.

La **estrategia de caché multinivel** reduce latencia y carga de backend. L1 cache en memoria Node.js usando Map o node-cache almacena datos frecuentemente accedidos como configuración y user sessions por 1-5 minutos. L2 cache en Redis almacena resultados de queries costosas de PostgreSQL por 5-60 minutos. L3 es PostgreSQL mismo con indexes apropiados. Esta arquitectura significa que request típico verifica L1 primero (latencia \<1ms), si miss verifica L2 (latencia 1-5ms), si miss consulta L3 PostgreSQL (latencia 10-50ms) y popular L2 y L1 para requests subsiguientes. La investigación muestra que con esta estrategia, 90%+ de requests se satisfacen desde L1 o L2, reduciendo carga de PostgreSQL dramáticamente.

**BullMQ para job processing** escala agregando workers dedicados que procesan jobs de la cola Redis. Para video transcoding que consume CPU/GPU intensivamente, los workers corren en servidores separados con GPUs NVIDIA para aceleración. La arquitectura típica incluye 4-8 workers para transcoding concurrente de videos, 2-4 workers para thumbnail generation, y 1-2 workers para tareas misceláneas. BullMQ distribuye automáticamente jobs entre workers disponibles, escalando throughput linealmente con número de workers. La priority queue permite que contenido urgente (livestream o update emergencia) salte al frente de la cola, procesándose inmediatamente mientras trabajos menos críticos esperan.

**Capacity planning** proyecta cuando necesitarás escalar. Para API layer, monitorea CPU usage y WebSocket connection count por instancia. Cuando CPU usage promedio supere 70% o connection count supere 80 por instancia, agrega otra instancia Node.js al load balancer. Para PostgreSQL, monitorea query latency (p95 debe estar \<50ms para reads, \<100ms para writes) y connection pool exhaustion. Cuando latency aumenta o pool se agota frecuentemente, agrega read replica. Para storage, agrega nodos MinIO cuando capacity supere 80% o cuando I/O wait en nodos existentes supere 20%. La tabla de recursos recomendados proyecta 12 CPU cores totales para API (3 servers × 4 cores), 8 cores para database primary, 16 cores por MinIO node, alcanzando aproximadamente 80 cores totales para deployment de 100 pantallas.

**Monitoring con Prometheus y Grafana** proporciona visibilidad esencial para capacity planning. Las métricas críticas incluyen: active WebSocket connections por server, HTTP request rate y latency (p50, p95, p99), database query performance, Redis cache hit ratio, storage usage por tier, y job queue length. Grafana dashboards muestran estas métricas en tiempo real, con alerts configurados para notificar cuando thresholds críticos se exceden. Por ejemplo, alert dispara cuando storage usage supera 85%, WebSocket disconnection rate supera 10%, o query latency p95 supera 200ms, permitiendo acción proactiva antes de que usuarios experimenten degradación.

## Recomendaciones de implementación y siguientes pasos

La implementación exitosa requiere roadmap claro que equilibre desarrollo rápido de MVP con arquitectura que escala. El plan recomendado divide el proyecto en cuatro fases de 4 semanas cada una, totalizando 16 semanas desde concepto hasta producción completa.

**Fase 1 (Semanas 1-4) establece fundamentos funcionales** con deployment monolítico single-server. Implementa backend Node.js + Express + Socket.io con TypeScript, conecta PostgreSQL single instance y Redis single instance, usa filesystem local para almacenamiento temporal de contenido. Desarrolla player React básico con HLS.js que conecta vía WebSocket y reproduce contenido sincronizado. Construye panel admin mínimo con upload de contenido, scheduling básico, y visualización de pantallas conectadas. Al finalizar esta fase, el sistema debe soportar 10-20 pantallas en entorno de prueba, permitiendo validar conceptos fundamentales antes de inversión mayor.

**Fase 2 (Semanas 5-8) añade alta disponibilidad y producción readiness**. Deploy HAProxy como load balancer frontend con sticky sessions. Implementa PostgreSQL streaming replication (1 primary + 1 replica) usando herramienta como repmgr o Patroni para gestión. Setup Redis Sentinel con 3 nodos para failover automático de cache. Migra storage a MinIO distributed con 4 nodos y erasure coding EC:4. Implementa monitoring completo con Prometheus + Grafana incluyendo dashboards de screen health, system performance, y storage usage. Configura PgBouncer para connection pooling. Esta fase prepara infraestructura para 50-100 pantallas con SLA de 99.9% uptime.

**Fase 3 (Semanas 9-12) optimiza performance y añade features avanzadas**. Implementa BullMQ con workers dedicados para video transcoding usando FFmpeg con GPU acceleration. Construye pipeline automático que detecta nuevo contenido, transcodes a escalera ABR completa, genera thumbnails, y notifica cuando está listo. Implementa storage tiering con MinIO lifecycle policies que mueven contenido antiguo a tier frío después de 90 días. Añade deduplicación mediante content-addressed storage usando SHA-256 hashes. Implementa caching strategy sofisticada con Nginx reverse proxy como CDN local. Añade features de admin panel como preview de contenido, programación avanzada con recurrencia, y grupos de pantallas para targeted content.

**Fase 4 (Semanas 13-16) completa feature set enterprise y valida escala**. Implementa multi-tenancy con hierarchical user management donde admin principal ve todo pero area managers solo ven sus pantallas asignadas. Construye analytics dashboard completo con métricas de reproducción, uptime por pantalla, content popularity, y user activity. Implementa sistema de alertas que notifica via Slack, email, o webhook cuando pantallas van offline, content falla al reproducir, o storage se acerca a capacidad. Ejecuta load testing exhaustivo simulando 150-200 pantallas concurrentes para validar que arquitectura maneja carga con margen. Documenta runbooks operacionales para tareas comunes y troubleshooting. Implementa disaster recovery plan con backups automáticos y procedimientos de restore testeados.

**Consideraciones de seguridad críticas** deben implementarse desde Fase 1. Usa TLS 1.3 para todas las conexiones (HTTPS, WSS) mediante certificados Let's Encrypt auto-renovables. Implementa rate limiting con express-rate-limit para prevenir abuse de API. Usa Helmet.js para headers de seguridad como CSP, HSTS, y X-Frame-Options. Almacena passwords hasheados con bcrypt (10+ rounds). Implementa RBAC con permisos granulares definidos en PostgreSQL. Configura firewall que permite solo ports necesarios (443 HTTPS, 3000 WebSocket) y whitelist IPs administrativas para endpoints sensibles.

**Testing automatizado** incluye unit tests con Jest para lógica de negocio crítica, integration tests para APIs usando Supertest, end-to-end tests con Playwright para workflows críticos de usuario en admin panel. Implementa también load testing con k6 o Artillery para validar performance bajo carga simulada de 100+ WebSocket connections concurrentes. CI/CD pipeline ejecuta todos los tests automáticamente en cada commit, bloqueando merge si algún test falla.

El **costo total estimado** para infraestructura on-premise que soporta 100 pantallas es aproximadamente $4,320 mensuales: 3 API servers (4 core, 8GB) a $450/mes, 3 database servers (8 core, 16GB) a $900/mes, 3 Redis nodes (2 core, 8GB) a $270/mes, 4 MinIO nodes (4 core, 16GB, 32TB) a $1,600/mes, 2 worker nodes (8 core, 16GB) a $600/mes, y networking 10 Gbps a $500/mes. Esto equivale a $43 por pantalla por mes. Cloud deployment en AWS costaría aproximadamente $5,800 mensuales o $58 por pantalla, 34% más caro pero con menor inversión inicial en hardware.

Los **key performance indicators** para monitorear post-launch incluyen: latencia de actualización de contenido (\<10 segundos target), uptime de pantallas (99%+ target), WebSocket connection stability (tasa de desconexión \<5% diaria), cache hit ratio (90%+ target), video transcoding time (10 minutos por 3GB target), y storage deduplication ratio (15-25% savings target). Dashboard de Grafana debe mostrar estos KPIs prominentemente, con alertas configuradas cuando desvían de targets.

Esta arquitectura proporciona foundation sólida y escalable que cumple todos los requerimientos técnicos: 100+ pantallas SmartTV con sincronización de 50-200ms, streaming eficiente de videos 3GB+ vía HLS adaptativo, caché local hasta 5GB por dispositivo en IndexedDB, failover automático con recuperación en menos de 30 segundos, actualizaciones de contenido en menos de 10 segundos, y escalabilidad clara hacia 500-1000 pantallas. El stack enteramente basado en tecnologías open-source elimina costos de licenciamiento mientras usa herramientas battle-tested con comunidades activas y soporte comercial disponible si necesario. La implementación por fases permite validación incremental reduciendo riesgo, mientras la arquitectura modular permite reemplazar componentes individuales sin rediseño completo si necesidades futuras lo requieren.
